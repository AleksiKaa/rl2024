{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332ba632",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc56fe3b197160f95e0ce17e7f74b52c",
     "grade": false,
     "grade_id": "cell-6bbaad78a2962d8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h2 align=\"center\"> <center><b> Reinforcement Learning Assignment 7 - Model Based Reinforcement Learning </b></center></h2>\n",
    "\n",
    "<br>\n",
    "<center><font size=\"3\">This notebook is a part of teaching material for ELEC-E8125</font></center>\n",
    "<center><font size=\"3\">Sep 4, 2024 - Nov 30, 2024</font></center>\n",
    "<center><font size=\"3\">Aalto University</font></center>\n",
    "</div>\n",
    "\n",
    "\n",
    "<a id='TOC'></a>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "# Table of contents\n",
    "* <a href='#1.'> 1. Introduction </a>\n",
    "* <a href='#1.1'> 1.1 Learning Objectives </a>\n",
    "* <a href='#1.2'> 1.2 Code Structure & Files </a>\n",
    "* <a href='#2.'> 2. Cross Entropy Method (CEM) </a>\n",
    "* <a href='#3.'> 3. Submitting </a>\n",
    "* <a href='#3.1'> 3.1 Feedback </a>\n",
    "* <a href='#4.'> References</a>\n",
    "\n",
    "<a href='#T1'><b>Student Task 1.</b> Implementing CEM (30 points)</a>\\\n",
    "<a href='#Q1'><b>Student Question 1.1</b> Changing Number of Samples (10 points)</a>\\\n",
    "<a href='#Q2'><b>Student Question 1.2</b> Model-free vs Mode-based RL (20 points)</a>\n",
    "    \n",
    "**Total Points:** 60\n",
    "\n",
    "**Estimated runtime of all the cells:** 1 hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013318a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea3c40f68451dbdf1f493519dcf50bf8",
     "grade": false,
     "grade_id": "cell-8459728c0f39fe2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Introduction <a id='1.'></a>\n",
    "In this exercise we will dive into model-based reinforcement learning. We will implement planning over several time steps. We will use the cross entropy method (CEM) to choose actions at each time step. CEM is often used in model-based reinforcement learning for choosing actions. The main working principles of CEM were explained during the lecture \"Model-based RL\". We use the simulator to simulate state transitions (another possibility would be to learn a dynamics model $s_{t+1} = f(s_t, a_t)$ to simulate state transitions if access to the system dynamics is not available).\n",
    "\n",
    "## 1.1 Learning Objectives: <a id='1.1'></a>\n",
    "- Understand how to get CEM planning working in practice\n",
    "- Understand limitations and advantages of model-based RL using CEM\n",
    "\n",
    "## 1.2 Code Structure & Files <a id='1.2'></a>\n",
    "\n",
    "You don‚Äôt have to edit any other file other than ```ex7.ipynb``` to complete this exercise.\n",
    "\n",
    "```\n",
    "‚îú‚îÄ‚îÄ‚îÄimgs                 # Images used in notebook\n",
    "‚îÇ   ex7_CEM.ipynb        # Main assignment file containing tasks <---------\n",
    "‚îÇ   env.py               # Wrappers for the environment\n",
    "|   simulator.py         # Using the exact environment as the model (simulator)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b96888e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ebdd7be95af65ae1ea447d70aae4e0c",
     "grade": false,
     "grade_id": "cell-486921177e95bc2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Warnings:\n",
    "\n",
    "- Don‚Äôt copy and paste cells within a notebook. This will mess up the tracking metadata and prevent autograding from working.\n",
    "- Only add new cells using the '+' button in the upper toolbar and do not split cells.\n",
    "- Be cautious about things such as copying the whole notebook to Colab to work on it. This has sometimes resulted in removing all notebook metadata, making autograding impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5197a537",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cca0b1c20f7e4923b32906539ba9219b",
     "grade": false,
     "grade_id": "cell-629362fc73796697",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. Cross Entropy Method (CEM) <a id='2.'></a>\n",
    "\n",
    "In this section, we will try to solve the **Cup-Catch** environment from the [DeepMind Control Suite](https://github.com/deepmind/dm_control/tree/main/dm_control/suite) by planning using CEM. \n",
    "\n",
    "In **Cup-Catch**, a ball is attached to a string which hangs from a cup. The goal is to swing the ball into the cup by moving the cup vertically up and down. The task has a sparse reward: 1 when the ball is in the cup, 0 otherwise. In order to save computation time we select an action every six time steps and use a wrapper to repeat the same action 6 times. Therefore, the maximum reward for each actual time step is 6.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/cup_catcher.png\" width=\"400px\">\n",
    "    <figcaption> Figure 1: Cup-Catch environment </figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e72ec92",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "030a904d4d4662a35b99821ff96b212d",
     "grade": false,
     "grade_id": "cell-a6fec760f8b4b43e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='T1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Task 1.</b> Implementing CEM (30 points) </h3> \n",
    "\n",
    "You need to complete the planning part in the code marked as ```TODO```. The code takes advantage of multiple processor cores by parallelizing the code. For more information about parallelizing, please check [Joblib](https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html). <br>\n",
    "    \n",
    "**Ensure that the notebook contains the reward plot.** \n",
    "\n",
    "The reference training plot is as Figure 2:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/cem_reward.png\">\n",
    "    <figcaption> Figure 2: Reward function at each time step in CEM </figcaption>\n",
    "</div>\n",
    "            \n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d3d8f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8257d5ca-400d-4526-a1fc-b6631d525060",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1328761886b85d75f2b783b42b65aded",
     "grade": true,
     "grade_id": "cell-88de2ac95f22f6f8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb546a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path # to find directory\n",
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from typing import Sequence, Tuple, Dict, Callable, List\n",
    "from functools import partial\n",
    "import copy, torch, time\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from env import make_env\n",
    "from simulator import SimulatorWrapper\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60671443-30df-4a7c-bffc-2e88a1fb70c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#!pip install mediapy # install a package required for video visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47668253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CEM(object):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model,\n",
    "        action_shape,\n",
    "        num_samples,\n",
    "        num_topk,\n",
    "        plan_horizon,\n",
    "        iteration,\n",
    "        keep_last_solution,\n",
    "        expl_noise\n",
    "    ):\n",
    "\n",
    "        self.model = model # the dynamics model\n",
    "\n",
    "        self.action_dim = action_shape[0]\n",
    "        self.num_samples = num_samples\n",
    "        self.num_topk = num_topk\n",
    "        self.plan_horizon = plan_horizon\n",
    "        self.iteration = iteration\n",
    "        self.keep_last_solution = keep_last_solution\n",
    "        self.expl_noise = expl_noise\n",
    "\n",
    "        # init simulator\n",
    "        o = self.model.reset()\n",
    "        self.model.save_checkpoint()\n",
    "        \n",
    "    def plan(self, obs, t0, eval_mode=False):\n",
    "        if obs.ndim == 1: obs = obs[None] # add batch dim\n",
    "        # initialize paramters\n",
    "        mean = np.zeros((self.plan_horizon, self.action_dim))\n",
    "        std = np.ones_like(mean)\n",
    "        # use previous plan as start point if not at the first step\n",
    "        if not t0 and hasattr(self, \"_prev_mean\"):\n",
    "            mean[:-1] = copy.copy(self._prev_mean[1:])\n",
    "\n",
    "        with Parallel(n_jobs=-1,) as parallel:  # we use joblib.Parallel to parallel the evaluation.\n",
    "            # Iterate CEM\n",
    "            for _ in range(self.iteration):\n",
    "                # TODO: Implement Cross-Entropy Method\n",
    "                \n",
    "                # Hints: \n",
    "                # 1. Generate random actions using Gaussian distribution with mean and std as parameters. \n",
    "                #    Use self.num_samples as the number of samples. Clip the samples to (-1, 1).\n",
    "                # 2. Perform Monte Carlo evaluation by computing the episode return for each sample using self.model as follows:\n",
    "                #    2.1. Use parallel(delayed(rollout_simulator)(self.model, action_sample) for each sample from 1.\n",
    "                # 3. Select top self.num_topk actions (elite actions) using episode returns from 2.1. Use numpy.argpartition.\n",
    "                # 4. Compute mean and std of elite actions and assign it to mean and std used in 1.\n",
    "                \n",
    "                ########## Your code starts here. ##########\n",
    "                \n",
    "                actions = np.random.normal(loc=mean, scale=std, size=(self.num_samples, *mean.shape))\n",
    "                actions = np.clip(actions, -1, 1)\n",
    "                returns = np.array(parallel(delayed(rollout_simulator)(self.model, action_sample) for action_sample in actions))\n",
    "                \n",
    "                elite_actions = actions[np.argpartition(returns, -self.num_topk)][-self.num_topk:]\n",
    "                \n",
    "                mean = np.mean(elite_actions, axis=0)\n",
    "                std = np.std(elite_actions, axis=0)\n",
    "                \n",
    "                ########## Your code ends here. ##########\n",
    "\n",
    "        if self.keep_last_solution:\n",
    "            self._prev_mean = mean\n",
    "\n",
    "        # select the first action in the planed horizon\n",
    "        action, std = mean[0], std[0]\n",
    "\n",
    "        if not eval_mode:\n",
    "            action += self.expl_noise * np.random.randn(action.shape)\n",
    "\n",
    "        # update the simulator state since simulator is used to do planning\n",
    "        next_obs, reward, done, info = self.model.step(action)\n",
    "        self.model.save_checkpoint()\n",
    "        \n",
    "        return action, info  \n",
    "        \n",
    "\n",
    "def rollout_simulator(model, traj):\n",
    "    model.load_checkpoint()\n",
    "\n",
    "    terminated, episode_return = False, 0\n",
    "    for act in traj:\n",
    "        obs, reward, done, _ = model.step(act)\n",
    "        reward = 0 if terminated else reward\n",
    "\n",
    "        terminated |= bool(done)\n",
    "        episode_return += reward\n",
    "        \n",
    "        if done: \n",
    "            break\n",
    "        \n",
    "    return episode_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0dfc4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note because of the action repeat a reward of 6 can be achieved from multiple steps being taken where the ball in the cup\n",
    "eval_env = make_env(\n",
    "    env_name='cup-catch',\n",
    "    seed=1,\n",
    "    action_repeat=6,\n",
    "    modality='pixels', \n",
    "    frame_stack=1,\n",
    "    img_size=(240, 320)\n",
    ")\n",
    "\n",
    "model_env = make_env(\n",
    "    env_name='cup-catch',\n",
    "    seed=1,\n",
    "    action_repeat=6\n",
    ")\n",
    "\n",
    "obs_shape = tuple(int(x) for x in eval_env.observation_space.shape)\n",
    "action_shape = tuple(int(x)  for x in eval_env.action_space.shape)\n",
    "\n",
    "model = SimulatorWrapper(model_env)\n",
    "\n",
    "agent = CEM(\n",
    "    model=model,\n",
    "    action_shape = action_shape,\n",
    "    num_samples=50,\n",
    "    num_topk=5,\n",
    "    plan_horizon=12,\n",
    "    iteration=5,\n",
    "    keep_last_solution=True,\n",
    "    expl_noise=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5bdc7-3a44-4c6e-9f27-d9550b9cc0a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if not skip_training:\n",
    "    obs, done, ep_reward, t = eval_env.reset(), False, 0, 0\n",
    "    rewards, observations = [], []\n",
    "    actions = []\n",
    "    with open(\"./cem_env.pkl\", 'wb') as f:\n",
    "        pickle.dump(eval_env, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    while not done and t < 20:\n",
    "        action, info = agent.plan(obs, eval_mode=True, t0=(t==0))\n",
    "        actions.append(action)\n",
    "        obs, reward, done, _ = eval_env.step(action)\n",
    "        rewards.append(reward)\n",
    "        observations.append(obs)\n",
    "\n",
    "        print(f'Timestep: {t} Reward: {reward}')\n",
    "        ep_reward += reward\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    with open(\"./cem_actions.pkl\", 'wb') as f:\n",
    "        pickle.dump(actions, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebcbc30d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd66b07c6302ce428c892f3595e7134c",
     "grade": true,
     "grade_id": "cell-ac4f6a68461e57ca",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\"TEST CELL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4399036-8ac8-450e-8abc-924b7cdb0d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    import mediapy \n",
    "    mediapy.write_video('video.mp4', [observations[i].transpose(1, 2, 0) for i in range(len(observations))], fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04b4f167-2f92-4239-aca4-da38c0923882",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    from IPython.display import Video # to display videos\n",
    "    Video(Path().cwd()/'video.mp4', embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aabdf29-028e-41af-b8fc-57e5eee59c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(rewards, linewidth=1.2, color='b')\n",
    "    plt.xticks(list(range(0, len(rewards), 2)))\n",
    "    plt.xlabel('Time step', fontsize=10)\n",
    "    plt.ylabel('Reward', fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76b6fa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd83ef8986451511be04621b95b24d9a",
     "grade": false,
     "grade_id": "cell-4060734fb67dba8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<a id='Q1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 1</b> Changing Number of Samples (5 points)</h3> \n",
    "\n",
    "<!-- Discuss the effect of changing the __number of samples__. How can this affect the performance and running time?             -->\n",
    "Which statement is correct? Choose one option.\n",
    "1. Increasing the number of samples (population) does not affect the performance, but it adds computational complexity, increasing the running time.\n",
    "2. Increasing the number of samples (population) enhances exploration and chance of finding the global optimum without any effect on the running time.\n",
    "3. Increasing the number of samples (population) enhances exploration and chance of finding the global optimum, but it requires more computation and it increases the running time consequently. However, parallel computing can be used to deal with extra computations.\n",
    "4. Increasing the number of samples (population) enhances exploration and chance of finding global optimum, but it requires more computation and running time, parallel computing cannot be used to accelerate computations.\n",
    "5. Increasing the number of samples (population) does not affect performance and running time.\n",
    "\n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "495b0103-2ddc-4038-8dac-e9d521258b6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sq1 = 3  # type: int  # replace ``None`` with your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1832ed15-8813-4c30-821d-bcf45c1fc51f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "717751861d56597e6a069d8ebd50f32e",
     "grade": false,
     "grade_id": "cell-2bf1e60d61c57590",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Do not remove or modify the following cells, which are used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75e8ca-87a6-4b95-b4ca-2e8660f7c673",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb9caa6b070683fb77d839280bf1dffd",
     "grade": true,
     "grade_id": "cell-d4beec6767d761c4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0611beaf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fe1221d6dbda144c9057629455d4932",
     "grade": false,
     "grade_id": "cell-a92458868dbc4fb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<a id='Q2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 1.2</b> Model-free vs Mode-based RL (20 points)</h3> \n",
    "\n",
    "<!-- Assume that the dynamics model $s_{t+1} = f(s_t, a_t)$ (when using a probabilistic dynamics model $P(s_{t+1}| s_t, a_t)$) and reward model $R(s_t, a_t)$ are learned from data during training. CEM with learned models can be used to solve similar tasks as model-free reinforcement learning methods such as DDPG.\n",
    "<br>\n",
    "In what kind of tasks do you expect CEM with learned models to work better than DDPG? In which kind of tasks do you expect DDPG to work better than CEM with learned models in terms of performance and training time? Why?\n",
    "<br>\n",
    "Which parts of CEM with a learned dynamics model need to be taken into account when considering computation time and why? -->\n",
    "Assume that the dynamics model $s_{t+1} = f(s_t, a_t)$ (when using a probabilistic dynamics model $P(s_{t+1}| s_t, a_t)$) and reward model $R(s_t, a_t)$ are learned from data during training. CEM with learned models can be used to solve similar tasks as model-free reinforcement learning methods such as DDPG.\n",
    "Select all correct statements, you can select 4 options at maximum.\n",
    "\n",
    "1. Generally speaking, CEM with learned models is more sample efficient than model-free methods like DDPG. CEM with learned models also requires approximately the same amount of computation in deployment compared to model-free methods.\n",
    "2. Model-free methods like DDPG are better suited for tasks with high dimensional observations (e.g. images) compared to CEM with learned models.\n",
    "3. In CEM with learned models, increasing the planning horizon always improves the performance given enough computations and time. \n",
    "4. Model-free methods like DDPG are better suited for deployment in real-time in applications with high frequency and limited hardware compared to CEM with learned models.\n",
    "5. Model-free methods like DDPG are better suited for tasks with complex non-smooth dynamics (e.g. high number of contacts) compared to CEM with learned models. \n",
    "6. When planning with learned models in CEM, it is possible to exploit the inaccuracies in the models, especially over longer horizons.\n",
    "7. Model-free methods like DDPG always converge to the optimal policy given enough samples, computation and time, but CEM with a learned model can converge to local optimum. \n",
    "8. Only neural networks are used to approximate the models based on data in CEM.\n",
    "9. Generally speaking, model-free methods like DDPG are robust to hyper-parameters while CEM with learned models require careful selection of hyper-parameters.\n",
    "\n",
    "    \n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0eeb594-5183-479f-8b94-9645ba029981",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq1_2 = [2, 4, 5, 9]  # write your options in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d8a7e-4bb1-463e-88ab-62270e20d05e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc98d73246826e3c69e9c5b0a21224c5",
     "grade": false,
     "grade_id": "cell-5ae9b539dbc750fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Do not remove or change the following cells, which are used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b65ac-19a5-4c7d-98f3-da2b26172abe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f5f4fb6d9638dcb4755d7b5d01ea291",
     "grade": true,
     "grade_id": "cell-35684b5b9baa07b6",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb57e87-6c25-4cb4-8d42-69e339e34d48",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "caecd5742bad19248c6e7794b616a565",
     "grade": true,
     "grade_id": "cell-10eb651f242ed7de",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5808663-5552-4fcd-9ac5-a1d50e8f6578",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "622e25a6052b11424f1975e24e9c22b1",
     "grade": true,
     "grade_id": "cell-d87f2ee26c2d6b92",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3358f-c8fe-410b-8d97-e9698bc48c86",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "434a6f84509c6607a69fe38aff7242ee",
     "grade": true,
     "grade_id": "cell-0e0cd9f0fe4e48b1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e950c66-7183-4d2e-afad-76d44e87ea7e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c033ef209349b08de23915fa7093de2",
     "grade": false,
     "grade_id": "cell-bdbb79444ad1285c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# 3. Submitting <a id='3.'></a>\n",
    "Ensure all tasks and questions (in ```ex7_MCTS.ipynb```) are answered and the relevant plots are recorded in the relevant places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09ad37af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa7a6ce07b76bbd59ee0b2291fb443a7",
     "grade": false,
     "grade_id": "cell-d6bc7fd592eee336",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure that skip training is set to True before submission\n",
    "assert skip_training == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e25649-58a0-448c-9fbc-7e055b20bc84",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1a3660bd4f1371f8d46628dc7808fd6",
     "grade": false,
     "grade_id": "cell-c9f3874f3ec059f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3.1 Feedback <a id='3.1'></a>\n",
    "\n",
    "In order to help the staff of the course as well as the forthcoming students, it would be great if you could answer to the following questions in your submission:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb0232-db2a-4e14-b075-9ef187b43b4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67e1ec5b64d964f2994c17e53a1d0a84",
     "grade": false,
     "grade_id": "cell-7e45dd3ec6737519",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "1) How much time did you spend solving this exercise? (change the ```hrs``` variable below to a floating point number representing the number of hours taken e.g. 5.43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac81f90-8902-4ed9-922b-b8ded5327c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52473cec-5ab3-439f-97ee-85c8796ec469",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1be266ca8ca87ebcb6f7f839d86896fc",
     "grade": false,
     "grade_id": "cell-c531100088cdf975",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2) Difficulty of each task/question from 1-5 (int or float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d71b2268-cbe3-4df8-a6d0-665aa425f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 4 # Student Task 1. Implementing CEM\n",
    "Q1 = 2 # Question 1.1: Number of samples\n",
    "Q2 = 4 # Question 2.1: Model-free vs Model-based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f3e791-b9fc-479c-871d-df4c85ab7dce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "064f028404ae2ff3c8cb5e9bbc64379a",
     "grade": false,
     "grade_id": "cell-d05ae3d7d4089cb7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3) How well did you understand the content of the task/question from 1-5? (int or float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62c8c9dd-26cb-4188-90e1-b7fad675da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = 3 # Student Task 1. Implementing CEM\n",
    "Q1 = 5 # Question 1.1: Number of samples\n",
    "Q2 = 3 # Question 2.1: Model-free vs Model-based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11c47c-3716-4642-adc5-c4569ac5fd8f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ddaaa911644fd6cadc02d81e59e40b3",
     "grade": false,
     "grade_id": "cell-08a621904100d675",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4) General feedback. Consider questions like:\n",
    "\n",
    "    - Did the content of the lecture relate well with the assignment?\n",
    "    - To what extent did you find the material to be potentially useful for your research and studies?\n",
    "    \n",
    "And other feedback you think is worth including. Type in the box below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9fd0e4-b0fe-4b59-8c8a-c0a51c24d5fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6464fd696b142961a9a276aa7100ce7e",
     "grade": false,
     "grade_id": "cell-657e754847f76fb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Please use the following section to record references.\n",
    "# References <a id='4.'></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552605a-ecef-401e-ae00-7a7009725bd4",
   "metadata": {
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
