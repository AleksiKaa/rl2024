{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73680d28-70d7-44bb-9978-7774f5eebf04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92013768fa2dde98629d49f929a72adc",
     "grade": false,
     "grade_id": "cell-7a4438007015663e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "   <h2 align=\"center\"> <center><b> Reinforcement Learning Assignment 7 - Model Based Reinforcement Learning </b></center></h2>\n",
    "\n",
    "<br>\n",
    "<center><font size=\"3\">This notebook is a part of teaching material for ELEC-E8125</font></center>\n",
    "<center><font size=\"3\">Sep 4, 2024 - Nov 30, 2024</font></center>\n",
    "<center><font size=\"3\">Aalto University</font></center>\n",
    "</div>\n",
    "\n",
    "\n",
    "<a id='TOC'></a>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "# Table of contents\n",
    "* <a href='#1.'> 1. Introduction </a>\n",
    "* <a href='#1.1'> 1.1 Learning Objectives </a>\n",
    "* <a href='#1.2'> 1.2 Code Structure & Files </a>\n",
    "* <a href='#2.'> 2. MCTS </a>\n",
    "* <a href='#3.'> 3. Submitting </a>\n",
    "* <a href='#3.1'> 3.1 Feedback </a>\n",
    "* <a href='#4.'> References</a>\n",
    "    \n",
    "<a href='#Q1'><b>Student Question 1</b> Difficulty of the task (10 points)</a>\\\n",
    "<a href='#T1'><b>Student Task 1.</b> Implementing MCTS (30 points)</a>\\\n",
    "<a href='#Q2'><b>Student Question 2</b> MCTS phases</a>\n",
    "    \n",
    "**Total Points:** 50\n",
    "\n",
    "**Estimated runtime of all the cells:** 1 hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb74a17-1c90-4f6b-90ea-d3164caf99a1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce63a7801a4b0c957ad23a56f54ad08f",
     "grade": false,
     "grade_id": "cell-b5f9ff0476a979c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Introduction <a id='1.'></a>\n",
    "In this section, we will use **Monte Carlo Tree Search (MCTS)** algorithm to solve **DeepSea** environment form [Behaviour Suite for Reinforcement Learning (bsuite)](https://github.com/google-deepmind/bsuite). The environment targets the challenge of exploration and represents a N√óN grid where the agent starts in the top left and has to reach a goal in the bottom right location. At each timestep, the agent moves one row down and can choose one out of two actions. The agent observes the current location and receives a small negative reward of -0.01/N  for moving right and 0 reward for moving left. Additionally, the agent receives a reward of +1 for reaching the goal (treasure) and the episode ends after N timesteps. In this exercise, the number of rows and columns (N) is 10. \n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/deep_sea.png\" width=\"400px\">\n",
    "    <figcaption> Figure 1: Deep-Sea environment </figcaption>\n",
    "</div>\n",
    "\n",
    "## 1.1 Learning Objectives: <a id='1.1'></a>\n",
    "- Understand different phases of MCTS\n",
    "- Implement a simplified version of MCTS\n",
    "\n",
    "## 1.2 Code Structure & Files <a id='1.2'></a>\n",
    "\n",
    "You don‚Äôt have to edit any other file other than ```ex7.ipynb``` to complete this exercise.\n",
    "\n",
    "```\n",
    "‚îú‚îÄ‚îÄ‚îÄimgs                 # Images used in notebook\n",
    "‚îÇ   ex7_MCTS.ipynb       # Main assignment file containing tasks <---------\n",
    "‚îÇ   env.py               # Wrappers for the environment\n",
    "‚îÇ   simulator.py         # Using the exact environment as the model (simulator)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07389788",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a1479b8852217cb08a4e6b6945945bb",
     "grade": false,
     "grade_id": "cell-1161460f522d4615",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Warnings:\n",
    "\n",
    "- Don‚Äôt copy and paste cells within a notebook. This will mess up the tracking metadata and prevent autograding from working.\n",
    "- Only add new cells using the '+' button in the upper toolbar and do not split cells.\n",
    "- Be cautious about things such as copying the whole notebook to Colab to work on it. This has sometimes resulted in removing all notebook metadata, making autograding impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54855efc-e89b-4386-938b-d6f4bf052f98",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49fb9c2571b9844e381ef10b3ec42a4d",
     "grade": false,
     "grade_id": "cell-2e69514b74cd5afa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<a id='Q1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 1.</b> Difficulty of the task (10 points)</h3> \n",
    "\n",
    "<!-- 1.1. What is the probability of reaching the goal state (a function of N) for **DeepSea** environment? <br>\n",
    "1.2. If N is large, DQN (with the $\\epsilon$-greedy policy) usually fail to reach the goal state (in fact, N=10 is already challenging for DQN). In this case, which strategy will DQN converge to? <br> -->\n",
    "Consider the DeepSea environment with a large N (number of columns and rows). DQN (with the  ùúñ-greedy policy) usually fail to reach the goal state (in fact, N=10 is already challenging for DQN). Which statement is correct?\n",
    "1. DQN will converge to a random policy with a probability of $0.5^{N-1}$ to reach the goal location. \n",
    "2. DQN will converge to a policy that always selects left action. The probability of reaching goal for a random agent is $0.5^{N-1}$\n",
    "3. DQN will converge to a policy that always selects left action, since  $\\epsilon$-greedy policy is used, the probability to reach the goal is $\\epsilon^{N-1}$. \n",
    "4. DQN will converge to a random policy with a probability of $\\epsilon^{N-1}$ to reach the goal location. \n",
    "\n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "    üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a489b2-f1bb-4e18-97c7-11935289c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq1 = 2  # replace ``None`` with your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58072844-b0c4-49f2-bf7b-b4384a4e8959",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e9ff90a72267345c8eee4bc04e3e7d5",
     "grade": false,
     "grade_id": "cell-62b6044c9069caf0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Do not remove or change the following cells, which are used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c3710-c90f-4a90-b0cb-92a7d2406e32",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcd7888268f268ed8fe3fe71b9ece020",
     "grade": true,
     "grade_id": "cell-1b9ec2492135c573",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ce37baa-7700-4167-b96b-5e65c990a881",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3addb61d184229f672e04593841bee0c",
     "grade": false,
     "grade_id": "cell-64cc824df69ad379",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# 2. MCTS <a id='2.'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081edfa-3417-44f7-9144-80cc5af076c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05daee6c267605498264bfc05deab752",
     "grade": false,
     "grade_id": "cell-e91f49b0fdcfffc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a id='T1'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Task 1.</b> Implement MCTS algorithm (30 points) </h3> \n",
    "\n",
    "Complete ```TODOs``` in the MCTS class below. Specifically, you need to: <br>\n",
    "1. finish the implementation of ```select_action``` method that selects the best action given the MCTS node using UCB1 exploration. <br>\n",
    "2. implement ```simulation``` method where you need to use best action to select the next node and expansion procedure of MCTS when there are no children.\n",
    "3. complete ```backpropagation``` method that updates the attributes of each node in the trajectory. <br>\n",
    "\n",
    "**Ensure that the notebook contains the average return plot.**\n",
    "\n",
    "The reference training plot is as Figure 2 (your plot might look different):\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"imgs/mcts_avg_return.png\">\n",
    "    <figcaption> Figure 2: Average episode return for MCTS on DeepSea environment </figcaption>\n",
    "</div>\n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f4f43aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28995bef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "497a818d3ceba4ec03b24cf83c2142aa",
     "grade": true,
     "grade_id": "cell-c539995f961eb78c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11df358-d684-4d7c-b8ee-d6b3f89258a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bsuite\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from env import BsuiteToGymWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "073067c6-6b04-4af9-954d-c1deb58fa1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### MCTS #####\n",
    "class Node(object):\n",
    "    \"\"\" A MCTS Node. \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reward: float = 0.\n",
    "        self.visit_count: int = 0\n",
    "        self.done: bool = False\n",
    "        self.total_value: float = 0.  # cumulative value\n",
    "        self.children: dict = {}  # children nodes, index is the action\n",
    "\n",
    "    def expand(self, num_action: int):\n",
    "        \"\"\" Expands this node by adding cild nodes. \"\"\"\n",
    "        for action in range(num_action):\n",
    "            self.children[action] = Node()\n",
    "    \n",
    "    @property\n",
    "    def value(self):  # Q(s, a)\n",
    "        \"\"\"Returns the value of this node.\"\"\"\n",
    "        if self.visit_count:\n",
    "            return self.total_value / self.visit_count\n",
    "        return 0.\n",
    "\n",
    "    @property\n",
    "    def children_visits(self) -> np.ndarray:\n",
    "        \"\"\"Return array of visit counts of visited children.\"\"\"\n",
    "        return np.array([c.visit_count for c in self.children.values()])\n",
    "\n",
    "    @property\n",
    "    def children_values(self) -> np.ndarray:\n",
    "        \"\"\"Return array of values of visited children.\"\"\"\n",
    "        return np.array([c.value for c in self.children.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bccd58bf-c6aa-4cd9-a6a4-5170018f0fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MCTS(object):\n",
    "    def __init__(self, env, discount = 1):\n",
    "        self.env = env\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.discount = discount\n",
    "        self.init_node = Node()\n",
    "        \n",
    "    def select_action(self, node, scale=1):\n",
    "        # TODO: implement selection phase of MCTS algorithm and return the best action.\n",
    "        # Hints:\n",
    "        # 1. If a node has no children, select the random action (use randint from NumPy).\n",
    "        # 2. Otherwise select the next node among node.children as follows:\n",
    "        #     2.1. Compute Q-value and UCB1 (Upper Confidence Bound 1) for node.children using node attributes (see Node class above).\n",
    "        #     2.2. Combine Q-value and UCB1 to balance exploration-exploitation tradeoff by considering scale coefficient.\n",
    "        #     2.3. Select the best action using results from 2.2.\n",
    "        ########## Your code starts here. ##########\n",
    "\n",
    "        if not node.children:\n",
    "            best_action = np.random.randint(self.num_actions)\n",
    "        else:          \n",
    "            eps = 1e-6 # To avoid div by zero\n",
    "            q_values = node.children_values\n",
    "            ucb1 = scale * np.sqrt((np.log(node.visit_count + 1)) / (node.children_visits + eps))\n",
    "            best_action = np.argmax(q_values + ucb1)\n",
    "        \n",
    "        ########## Your code ends here. ##########\n",
    "        \n",
    "        return best_action\n",
    "\n",
    "    def simulation(self):\n",
    "        state = self.env.reset()\n",
    "        node = self.init_node\n",
    "        trajectory = [node]\n",
    "\n",
    "        while not node.done:\n",
    "            # TODO: perform simulation phase of MCTS and return the trajectory of MCTS nodes.\n",
    "            # Hints:\n",
    "            # 1. Use self.select_action to select best action for each node.\n",
    "            # 2. Use the best action in self.env.step to get the next state, reward and done.\n",
    "            # 2. If node has no children, use node.expand to perform MCTS expansion phase.\n",
    "            # 3. Use node.children attribute to assign node to the best child of current node.\n",
    "            # 4. Update node.reward and node.done with reward and done values from 2.\n",
    "            # 5. Add node to the trajectory list.\n",
    "            ########## Your code starts here. ##########\n",
    "            \n",
    "            action = self.select_action(node)\n",
    "            _, reward, done, _ = self.env.step(action)\n",
    "            \n",
    "            if not node.children:\n",
    "                node.expand(self.num_actions)\n",
    "\n",
    "            node = node.children[action]\n",
    "            node.reward = reward\n",
    "            node.done = done\n",
    "            trajectory.append(node)\n",
    "            \n",
    "            ########## Your code ends here. ##########\n",
    "        \n",
    "        return trajectory\n",
    "\n",
    "    def backpropagation(self, trajectory):\n",
    "        ep_return = 0\n",
    "        while trajectory:\n",
    "            node = trajectory.pop()\n",
    "            # TODO: implement backpropagation phase of MCTS and return the discounted sum of rewards\n",
    "            # Hints:\n",
    "            # 1. Multiply episode return by self.discount.\n",
    "            # 2. Add node return to episode return. \n",
    "            # 3. Update node total_value with episode return and increase visit_count.\n",
    "            ########## Your code starts here. ##########\n",
    "            ep_return *= self.discount\n",
    "            ep_return += node.reward\n",
    "            node.total_value += ep_return\n",
    "            node.visit_count += 1\n",
    "            ########## Your code ends here. ##########\n",
    "            \n",
    "        return ep_return\n",
    "\n",
    "    def run(self, num_iteration):\n",
    "        returns = []\n",
    "        for iter in range(num_iteration):\n",
    "            trajectory = self.simulation()\n",
    "            episode_return = self.backpropagation(trajectory)\n",
    "            returns.append(episode_return)\n",
    "            \n",
    "        return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67408669-c97e-446b-8517-390586caae54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = bsuite.load_from_id('deep_sea/0')\n",
    "env = BsuiteToGymWrapper(env)\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74d91f7c-db90-4d15-817a-1896fed87c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = MCTS(env)\n",
    "returns = agent.run(num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e82a7c24-a9b6-4806-a89c-22af633d821b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# computes average of last 50 episodes\n",
    "num_episodes = 2000\n",
    "avg_returns = [np.mean(returns[-50+i:i]) for i in range(50, num_episodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c60675b9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89e82acf42ee4da82f4e6f61fa542c9c",
     "grade": true,
     "grade_id": "cell-7aeaa7656188b643",
     "locked": true,
     "points": 30,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\"TEST CELL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ba409-146d-4a2a-83cc-a7877c3a5126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(avg_returns, linewidth=1.2, color='b')\n",
    "    plt.xlabel('Episodes', fontsize=10)\n",
    "    plt.ylabel('Return', fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8d5d7-d6c4-4b95-98e0-cfde0fbba0c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41bdfd18a7b71f17bb443476ed6a4a7a",
     "grade": false,
     "grade_id": "cell-1a1ccb076e6eff79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<a id='Q2'></a>\n",
    "<div class=\" alert alert-warning\">\n",
    "    <h3><b>Student Question 2.</b> MCTS algorithm (5 points)</h3> \n",
    "<!-- Describe different phases in MCTS. Explain each one briefly in your own words. -->\n",
    "Which statement is correct?\n",
    "    \n",
    "1. In MCTS, selection refers to choosing a random action for leaf nodes.\n",
    "2. In MCTS, only Q values are used to make a decision.\n",
    "3. In MCTS backpropagation step, nodes are updated from the root of the tree to the leaf nodes. \n",
    "4. In MCTS, simulation step is is used until reaching a leaf node\n",
    "5. In MCTS selection step, unvisited nodes are always prioritized.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "üîù\t<a href='#TOC'><b>Table of Contents</b></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead519a9-13b3-45cd-b7f4-d815c5752979",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq2 = 4  # replace ``None`` with your option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a8cfe-403a-4551-beb0-f54068353527",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c70aaa7698d32e13c788462e773d3b0",
     "grade": false,
     "grade_id": "cell-e860805f6fc4a116",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Do not remove or change the following cells, which are used for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d3cfe-2b0f-4965-a576-a092588d92b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f938ac0895cc92d01a975ea7d437390",
     "grade": true,
     "grade_id": "cell-834ede63376a248e",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a659d502-725a-41f7-a1ad-fac876681fb6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e25fe32672b7d5140faeaab1ace19b8",
     "grade": false,
     "grade_id": "cell-e51e4fa7297bf55b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# 3. Submitting <a id='3.'></a>\n",
    "Ensure all tasks and questions (in ```ex7_MCTS.ipynb```) are answered and the relevant plots are recorded in the relevant places. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f336ffa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fa3b8ae17df8983a188117dba681985",
     "grade": false,
     "grade_id": "cell-b7fd3274e4c871b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure that skip training is set to True before submission\n",
    "assert skip_training == True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e45412-1af0-4524-baba-548e88ad4992",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fe2c1b463d63a7e4964d11e6c6b8a07",
     "grade": false,
     "grade_id": "cell-914fe6f76c307ab8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3.1 Feedback <a id='3.1'></a>\n",
    "\n",
    "In order to help the staff of the course as well as the forthcoming students, it would be great if you could answer to the following questions in your submission:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364da21-6c7f-4c68-b35a-e308b3f1acff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7871e6cf13daa780211f855812be2a1a",
     "grade": false,
     "grade_id": "cell-2454b332639fcb9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "1) How much time did you spend solving this exercise? (change the ```hrs``` variable below to a floating point number representing the number of hours taken e.g. 5.43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47684b1f-c2de-42d5-9eba-56ebe6ab4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8286772-df2e-4e9d-a783-24acdcbcbbd2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94fdad1362acd0df454cc9af03ac3d98",
     "grade": false,
     "grade_id": "cell-8cc6e24aa3c62a32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "2) Difficulty of each task/question from 1-5 (int or float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a41a89e6-b33d-4f38-b169-6e871041c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = None # Student Task 1. Implementing MCTS\n",
    "Q1 = None # Question 1.1: Difficulty of the task\n",
    "Q2 = None # Question 2.1: MCTS phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00739461-6f94-43d6-a65a-9a509d061340",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "746fafdbb661c12eaf0b8ee8d98e8078",
     "grade": false,
     "grade_id": "cell-2b4aa5375be069bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "3) How well did you understand the content of the task/question from 1-5? (int or float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a12a922-a3d4-4297-b1a1-e5819a946949",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = None # Student Task 1. Implementing MCTS\n",
    "Q1 = None # Question 1.1: Difficulty of the task\n",
    "Q2 = None # Question 2.1: MCTS phases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f95cba-7e62-4cda-b058-8134b4daa09f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07a28ff7125c49c2d42aea974e6e89b6",
     "grade": false,
     "grade_id": "cell-891d9586161db3f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "4) General feedback. Consider questions like:\n",
    "\n",
    "    - Did the content of the lecture relate well with the assignment?\n",
    "    - To what extent did you find the material to be potentially useful for your research and studies?\n",
    "    \n",
    "And other feedback you think is worth including. Type in the box below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172714f-3c83-49b1-8e7a-35390c490a96",
   "metadata": {},
   "source": [
    "Your feedback here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a57ceb-9879-448b-bdc8-a38af34da4f1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68589e7ed9b5f2e54a096a504dd8b597",
     "grade": false,
     "grade_id": "cell-52de150028239934",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Please use the following section to record references.\n",
    "# References <a id='4.'></a>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
